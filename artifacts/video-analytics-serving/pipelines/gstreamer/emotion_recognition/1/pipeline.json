{
	"type": "GStreamer",
	"template": ["urisourcebin name=source ! concat name=c ! decodebin ! video/x-raw ",
				" ! videoconvert name=videoconvert",
				" ! gvadetect model={models[face_detection_retail][1][network]} name=detection",
				" ! queue ! gvaclassify model={models[emotion_recognition][1][network]} name=classification",
				" ! queue ! gvametaconvert name=metaconvert ! queue ! gvametapublish name=destination",
				" ! appsink name=appsink"
				],
	"description": "Emotion Recognition Pipeline",
	"parameters": {
		"type": "object",
		"properties": {
			"device": {
				"element": "detection",
				"type": "string",
				"enum": [
					"CPU",
					"HDDL",
					"GPU",
					"VPU",
					"MYRIAD"
				]
			},
			"detection-model-instance-id": {
				"element": {
					"name": "detection",
					"property": "model-instance-id"
				},
				"type": "string",
				"default": "face_detection_retail0"
			},
			"classification-model-instance-id": {
				"element": {
					"name": "classification",
					"property": "model-instance-id"
				},
				"type": "string",
				"default": ""
			},
			"inference-interval": {
				"element": "detection",
				"type": "integer",
				"minimum": 1,
				"maximum": 4294967295,
				"default": 1
			},
			"cpu-throughput-streams": {
				"element": "detection",
				"type": "integer"
			},
			"n-threads": {
				"element": "videoconvert",
				"type": "integer",
				"default": 1
			},
			"nireq": {
				"element": "detection",
				"type": "integer",
				"minimum": 1,
				"maximum": 1024,
				"default": 2
			}
		}
	}
}
